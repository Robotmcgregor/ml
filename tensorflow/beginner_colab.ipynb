{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tce3stUlHN0L"
   },
   "source": [
    "##### Copyright 2022 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "tuOe1ymfHZPu"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36EdAGhThQov"
   },
   "source": [
    "# Build, train and evaluate models with TensorFlow Decision Forests\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/decision_forests/tutorials/beginner_colab\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/decision-forests/blob/main/documentation/tutorials/beginner_colab.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/decision-forests/blob/main/documentation/tutorials/beginner_colab.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/decision-forests/documentation/tutorials/beginner_colab.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvvDY0LVhuaW"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Decision Forests (DF) are a family of Machine Learning algorithms for\n",
    "supervised classification, regression and ranking. As the name suggests, DFs use\n",
    "decision trees as a building block. Today, the two most popular DF training\n",
    "algorithms are [Random Forests](https://en.wikipedia.org/wiki/Random_forest) and\n",
    "[Gradient Boosted Decision Trees](https://en.wikipedia.org/wiki/Gradient_boosting).\n",
    "\n",
    "TensorFlow Decision Forests (TF-DF) is a library for the training,\n",
    "evaluation, interpretation and inference of Decision Forest models.\n",
    "\n",
    "In this tutorial, you will learn how to:\n",
    "\n",
    "1.  Train a multi-class classification Random Forest on a dataset containing numerical, categorical and missing features.\n",
    "1.  Evaluate the model on a test dataset.\n",
    "1.  Prepare the model for\n",
    "    [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving).\n",
    "1.  Examine the overall structure of the model and the importance of each feature.\n",
    "1.  Re-train the model with a different learning algorithm (Gradient Boosted Decision Trees).\n",
    "1.  Use a different set of input features.\n",
    "1.  Change the hyperparameters of the model.\n",
    "1.  Preprocess the features.\n",
    "1.  Train a model for regression.\n",
    "\n",
    "Detailed documentation is available in the [user manual](https://github.com/tensorflow/decision-forests/tree/main/documentation).\n",
    "The [example directory](https://github.com/tensorflow/decision-forests/tree/main/examples) contains other end-to-end examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jK9tCTcwqq4k"
   },
   "source": [
    "## Installing TensorFlow Decision Forests\n",
    "\n",
    "Install TF-DF by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_decision_forests==1.8.1 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow_decision_forests==1.8.1) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow_decision_forests==1.8.1) (2.2.1)\n",
      "Collecting tensorflow~=2.15.0 (from tensorflow_decision_forests==1.8.1)\n",
      "  Using cached tensorflow-2.15.1-cp310-cp310-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: six in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow_decision_forests==1.8.1) (1.16.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow_decision_forests==1.8.1) (2.1.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow_decision_forests==1.8.1) (0.41.2)\n",
      "Requirement already satisfied: wurlitzer in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow_decision_forests==1.8.1) (3.0.3)\n",
      "Collecting tensorflow-intel==2.15.1 (from tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1)\n",
      "  Using cached tensorflow_intel-2.15.1-cp310-cp310-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (24.3.7)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (4.25.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (68.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (1.62.1)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1)\n",
      "  Using cached tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (2.15.0)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1)\n",
      "  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from pandas->tensorflow_decision_forests==1.8.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from pandas->tensorflow_decision_forests==1.8.1) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from pandas->tensorflow_decision_forests==1.8.1) (2024.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (2.28.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (3.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests==1.8.1) (3.2.2)\n",
      "Using cached tensorflow-2.15.1-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Using cached tensorflow_intel-2.15.1-cp310-cp310-win_amd64.whl (300.9 MB)\n",
      "Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Using cached tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
      "Installing collected packages: keras, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.0.5\n",
      "    Uninstalling keras-3.0.5:\n",
      "      Successfully uninstalled keras-3.0.5\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.16.2\n",
      "    Uninstalling tensorboard-2.16.2:\n",
      "      Successfully uninstalled tensorboard-2.16.2\n",
      "  Attempting uninstall: tensorflow-intel\n",
      "    Found existing installation: tensorflow-intel 2.16.1\n",
      "    Uninstalling tensorflow-intel-2.16.1:\n",
      "      Successfully uninstalled tensorflow-intel-2.16.1\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.16.1\n",
      "    Uninstalling tensorflow-2.16.1:\n",
      "      Successfully uninstalled tensorflow-2.16.1\n",
      "Successfully installed keras-2.15.0 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-intel-2.15.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.15.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_decision_forests==1.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf_keras==2.15.0\n",
      "  Downloading tf_keras-2.15.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tf_keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.7 MB 1.1 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.3/1.7 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.7 MB 3.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.9/1.7 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.0/1.7 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.0/1.7 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.0/1.7 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.7 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.6/1.7 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 3.5 MB/s eta 0:00:00\n",
      "Installing collected packages: tf_keras\n",
      "  Attempting uninstall: tf_keras\n",
      "    Found existing installation: tf_keras 2.16.0\n",
      "    Uninstalling tf_keras-2.16.0:\n",
      "      Successfully uninstalled tf_keras-2.16.0\n",
      "Successfully installed tf_keras-2.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tf_keras==2.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Pa1Pf37RhEYN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_decision_forests in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow_decision_forests) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow_decision_forests) (2.2.1)\n",
      "Requirement already satisfied: tensorflow~=2.15.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow_decision_forests) (2.15.1)\n",
      "Requirement already satisfied: six in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow_decision_forests) (1.16.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow_decision_forests) (2.1.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow_decision_forests) (0.41.2)\n",
      "Requirement already satisfied: wurlitzer in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow_decision_forests) (3.0.3)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.1 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.15.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (24.3.7)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (4.25.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (68.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (2.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from pandas->tensorflow_decision_forests) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from pandas->tensorflow_decision_forests) (2024.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (2.28.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (3.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.1->tensorflow~=2.15.0->tensorflow_decision_forests) (3.2.2)\n",
      "Requirement already satisfied: tf_keras in c:\\users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages (2.15.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer<4,>=2 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.2.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2023.11.17)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.1.4)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipp>=0.5 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.17.0)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (0.5.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.2.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached tensorflow_decision_forests-1.8.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.3 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: wurlitzer, tensorflow_decision_forests\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed tensorflow_decision_forests-1.8.1 wurlitzer-3.0.3\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf_keras in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (2.15.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_decision_forests\n",
    "# TF-DF requires Tensorflow < 2.15 or tf_keras\n",
    "!pip install tf_keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZGda2dOe-hH"
   },
   "source": [
    "[Wurlitzer](https://pypi.org/project/wurlitzer/) is needed to display the detailed training logs in Colabs (when using `verbose=2` in the model constructor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lk26uBSCe8Du"
   },
   "outputs": [],
   "source": [
    "!pip install wurlitzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3oinwbhXlggd"
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "52W45tmDjD64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:TensorFlow Decision Forests 1.8.1 is compatible with the following TensorFlow Versions: ['2.15.0']. However, TensorFlow 2.15.1 was detected. This can cause issues with the TF API and symbols in the custom C++ ops. See the TF and TF-DF compatibility table at https://github.com/tensorflow/decision-forests/blob/main/documentation/known_issues.md#compatibility-table.\n",
      "WARNING:root:Failure to load the inference.so custom c++ tensorflow ops. This error is likely caused the version of TensorFlow and TensorFlow Decision Forests are not compatible. Full error:C:\\Users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\inference.so not found\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "C:\\Users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\inference.so not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Keep using Keras 2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTF_USE_LEGACY_KERAS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfdf\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_decision_forests\\__init__.py:64\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_version\n\u001b[0;32m     62\u001b[0m check_version\u001b[38;5;241m.\u001b[39mcheck_version(__version__, compatible_tf_versions)\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m py_tree\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m builder\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_decision_forests\\keras\\__init__.py:53\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Decision Forest in a Keras Model.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mUsage example:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, List\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wrappers\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Utility classes\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_decision_forests\\keras\\core.py:62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inspector \u001b[38;5;28;01mas\u001b[39;00m inspector_lib\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tuner \u001b[38;5;28;01mas\u001b[39;00m tuner_lib\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core_inference\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cc_logging\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core \u001b[38;5;28;01mas\u001b[39;00m tf_core\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_decision_forests\\keras\\core_inference.py:36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core_inference \u001b[38;5;28;01mas\u001b[39;00m tf_core\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_logging\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m tf_op\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myggdrasil_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlearner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m abstract_learner_pb2\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myggdrasil_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlearner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultitasker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multitasker_pb2\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\api.py:179\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inspector \u001b[38;5;28;01mas\u001b[39;00m inspector_lib\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf1_compatibility\n\u001b[1;32m--> 179\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m op\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myggdrasil_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_spec_pb2\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myggdrasil_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m abstract_model_pb2\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\op.py:15\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2021 Google LLC.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mop_dynamic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\op_dynamic.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     23\u001b[0m   check_version\u001b[38;5;241m.\u001b[39minfo_fail_to_load_custom_op(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference.so\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Importing all the symbols.\u001b[39;00m\n\u001b[0;32m     27\u001b[0m module \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;18m__name__\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\op_dynamic.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m   ops \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_op_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_path_to_datafile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minference.so\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     23\u001b[0m   check_version\u001b[38;5;241m.\u001b[39minfo_fail_to_load_custom_op(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference.so\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\load_library.py:54\u001b[0m, in \u001b[0;36mload_op_library\u001b[1;34m(library_filename)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_op_library\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_op_library\u001b[39m(library_filename):\n\u001b[0;32m     33\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a TensorFlow plugin, containing custom ops and kernels.\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m  Pass \"library_filename\" to a platform-specific mechanism for dynamically\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m    RuntimeError: when unable to load the library or get the python wrappers.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m   lib_handle \u001b[38;5;241m=\u001b[39m \u001b[43mpy_tf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_LoadLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlibrary_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m     wrappers \u001b[38;5;241m=\u001b[39m _pywrap_python_op_gen\u001b[38;5;241m.\u001b[39mGetPythonWrappers(\n\u001b[0;32m     57\u001b[0m         py_tf\u001b[38;5;241m.\u001b[39mTF_GetOpList(lib_handle))\n",
      "\u001b[1;31mNotFoundError\u001b[0m: C:\\Users\\robot\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\inference.so not found"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Keep using Keras 2\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
    "import tensorflow_decision_forests as tfdf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tf_keras\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check the version of TensorFlow Decision Forests\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorFlow Decision Forests v\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mtfdf\u001b[49m\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras v\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m tf_keras\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tfdf' is not defined"
     ]
    }
   ],
   "source": [
    "# Check the version of TensorFlow Decision Forests\n",
    "print(\"TensorFlow Decision Forests v\" + tfdf.__version__)\n",
    "print(\"Keras v\" + tf_keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LPPwWxYxtDM"
   },
   "source": [
    "The hidden code cell limits the output height in colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "2AhqJz3VmQM-"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "\n",
    "from IPython.core.magic import register_line_magic\n",
    "from IPython.display import Javascript\n",
    "from IPython.display import display as ipy_display\n",
    "\n",
    "# Some of the model training logs can cover the full\n",
    "# screen if not compressed to a smaller viewport.\n",
    "# This magic allows setting a max height for a cell.\n",
    "@register_line_magic\n",
    "def set_cell_height(size):\n",
    "  ipy_display(\n",
    "      Javascript(\"google.colab.output.setIframeHeight(0, true, {maxHeight: \" +\n",
    "                 str(size) + \"})\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8gVQ-txtjFU4"
   },
   "outputs": [],
   "source": [
    "# Check the version of TensorFlow Decision Forests\n",
    "print(\"Found TensorFlow Decision Forests v\" + tfdf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGRtRECujKeu"
   },
   "source": [
    "## Training a Random Forest model\n",
    "\n",
    "In this section, we train, evaluate, analyse and export a multi-class classification Random Forest trained on the [Palmer's Penguins](https://allisonhorst.github.io/palmerpenguins/articles/intro.html) dataset.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://allisonhorst.github.io/palmerpenguins/reference/figures/lter_penguins.png\" width=\"150\"/></center>\n",
    "\n",
    "**Note:** The dataset was exported to a csv file without pre-processing: `library(palmerpenguins); write.csv(penguins, file=\"penguins.csv\", quote=F, row.names=F)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qsSU1RfmNiP"
   },
   "source": [
    "### Load the dataset and convert it in a tf.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nJ5igfElg2I"
   },
   "source": [
    "This dataset is very small (300 examples) and stored as a .csv-like file. Therefore, use Pandas to load it.\n",
    "\n",
    "**Note:** Pandas is practical as you don't have to type in name of the input features to load them. For larger datasets (>1M examples), using the\n",
    "[TensorFlow Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) to read the files may be better suited.\n",
    "\n",
    "Let's assemble the dataset into a csv file (i.e. add the header), and load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44Jq6g_mJFmj"
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "!wget -q https://storage.googleapis.com/download.tensorflow.org/data/palmer_penguins/penguins.csv -O /tmp/penguins.csv\n",
    "\n",
    "# Load a dataset into a Pandas Dataframe.\n",
    "dataset_df = pd.read_csv(\"/tmp/penguins.csv\")\n",
    "\n",
    "# Display the first 3 examples.\n",
    "dataset_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23AewWT1lkIK"
   },
   "source": [
    "The dataset contains a mix of numerical (e.g. `bill_depth_mm`), categorical\n",
    "(e.g. `island`) and missing features. TF-DF supports all these feature types natively (differently than NN based models), therefore there is no need for preprocessing in the form of one-hot encoding, normalization or extra `is_present` feature.\n",
    "\n",
    "Labels are a bit different: Keras metrics expect integers. The label (`species`) is stored as a string, so let's convert it into an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uO_jz2sj0IBZ"
   },
   "outputs": [],
   "source": [
    "# Encode the categorical labels as integers.\n",
    "#\n",
    "# Details:\n",
    "# This stage is necessary if your classification label is represented as a\n",
    "# string since Keras expects integer classification labels.\n",
    "# When using `pd_dataframe_to_tf_dataset` (see below), this step can be skipped.\n",
    "\n",
    "# Name of the label column.\n",
    "label = \"species\"\n",
    "\n",
    "classes = dataset_df[label].unique().tolist()\n",
    "print(f\"Label classes: {classes}\")\n",
    "\n",
    "dataset_df[label] = dataset_df[label].map(classes.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwJjLFhbtozI"
   },
   "source": [
    "Next split the dataset into training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7DEIxn2oB3U"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into a training and a testing dataset.\n",
    "\n",
    "def split_dataset(dataset, test_ratio=0.30):\n",
    "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
    "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "  return dataset[~test_indices], dataset[test_indices]\n",
    "\n",
    "\n",
    "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
    "print(\"{} examples in training, {} examples for testing.\".format(\n",
    "    len(train_ds_pd), len(test_ds_pd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWq7uQcCuBzO"
   },
   "source": [
    "And finally, convert the pandas dataframe (`pd.Dataframe`) into tensorflow datasets (`tf.data.Dataset`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qtXgUBKluTX0"
   },
   "outputs": [],
   "source": [
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label)\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRKLWIWNuOZ1"
   },
   "source": [
    "**Notes:** Recall that `pd_dataframe_to_tf_dataset` converts string labels to integers if necessary.\n",
    "\n",
    "If you want to create the `tf.data.Dataset` yourself, there are a couple of things to remember:\n",
    "\n",
    "- The learning algorithms work with a one-epoch dataset and without shuffling.\n",
    "- The batch size does not impact the training algorithm, but a small value might slow down reading the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYAoyfYtqHG4"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xete-FbuqJCV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:03.671866. Found 248 examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training gets stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:17.7858 UTC kernel.cc:771] Start Yggdrasil model training\n",
      "[INFO 24-01-31 12:18:17.7858 UTC kernel.cc:772] Collect training examples\n",
      "[INFO 24-01-31 12:18:17.7859 UTC kernel.cc:785] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: false\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "[INFO 24-01-31 12:18:17.7862 UTC kernel.cc:391] Number of batches: 1\n",
      "[INFO 24-01-31 12:18:17.7862 UTC kernel.cc:392] Number of examples: 248\n",
      "[INFO 24-01-31 12:18:17.7863 UTC kernel.cc:792] Training dataset:\n",
      "Number of records: 248\n",
      "Number of columns: 8\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 5 (62.5%)\n",
      "\tCATEGORICAL: 3 (37.5%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 5 (62.5%)\n",
      "\t1: \"bill_depth_mm\" NUMERICAL num-nas:1 (0.403226%) mean:17.1433 min:13.2 max:21.2 sd:1.94504\n",
      "\t2: \"bill_length_mm\" NUMERICAL num-nas:1 (0.403226%) mean:43.8749 min:32.1 max:59.6 sd:5.55021\n",
      "\t3: \"body_mass_g\" NUMERICAL num-nas:1 (0.403226%) mean:4185.93 min:2700 max:6300 sd:777.438\n",
      "\t4: \"flipper_length_mm\" NUMERICAL num-nas:1 (0.403226%) mean:200.53 min:172 max:231 sd:13.9248\n",
      "\t7: \"year\" NUMERICAL mean:2008 min:2007 max:2009 sd:0.813198\n",
      "\n",
      "CATEGORICAL: 3 (37.5%)\n",
      "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:4 no-ood-item\n",
      "\t5: \"island\" CATEGORICAL has-dict vocab-size:4 zero-ood-items most-frequent:\"Biscoe\" 116 (46.7742%)\n",
      "\t6: \"sex\" CATEGORICAL num-nas:9 (3.62903%) has-dict vocab-size:3 zero-ood-items most-frequent:\"female\" 121 (50.6276%)\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "[INFO 24-01-31 12:18:17.7863 UTC kernel.cc:808] Configure learner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:17.7865 UTC kernel.cc:822] Training config:\n",
      "learner: \"RANDOM_FOREST\"\n",
      "features: \"^bill_depth_mm$\"\n",
      "features: \"^bill_length_mm$\"\n",
      "features: \"^body_mass_g$\"\n",
      "features: \"^flipper_length_mm$\"\n",
      "features: \"^island$\"\n",
      "features: \"^sex$\"\n",
      "features: \"^year$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 123456\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "  num_trees: 300\n",
      "  decision_tree {\n",
      "    max_depth: 16\n",
      "    min_examples: 5\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: 0\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      cart {\n",
      "      }\n",
      "    }\n",
      "    axis_aligned_split {\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "  }\n",
      "  winner_take_all_inference: true\n",
      "  compute_oob_performances: true\n",
      "  compute_oob_variable_importances: false\n",
      "  num_oob_variable_importances_permutations: 1\n",
      "  bootstrap_training_dataset: true\n",
      "  bootstrap_size_ratio: 1\n",
      "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "  sampling_with_replacement: true\n",
      "}\n",
      "\n",
      "[INFO 24-01-31 12:18:17.7868 UTC kernel.cc:825] Deployment config:\n",
      "cache_path: \"/tmpfs/tmp/tmp3eddfnse/working_cache\"\n",
      "num_threads: 32\n",
      "try_resume_training: true\n",
      "\n",
      "[INFO 24-01-31 12:18:17.7870 UTC kernel.cc:887] Train model\n",
      "[INFO 24-01-31 12:18:17.7871 UTC random_forest.cc:416] Training random forest on 248 example(s) and 7 feature(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:17.7928 UTC random_forest.cc:802] Training of tree  1/300 (tree index:1) done accuracy:0.952941 logloss:1.69617\n",
      "[INFO 24-01-31 12:18:17.7930 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.961864 logloss:0.671715\n",
      "[INFO 24-01-31 12:18:17.7932 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.967078 logloss:0.503792\n",
      "[INFO 24-01-31 12:18:17.7934 UTC random_forest.cc:802] Training of tree  31/300 (tree index:33) done accuracy:0.971774 logloss:0.219305\n",
      "[INFO 24-01-31 12:18:17.7936 UTC random_forest.cc:802] Training of tree  42/300 (tree index:37) done accuracy:0.967742 logloss:0.0889185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:17.7937 UTC random_forest.cc:802] Training of tree  53/300 (tree index:54) done accuracy:0.967742 logloss:0.0857322\n",
      "[INFO 24-01-31 12:18:17.7941 UTC random_forest.cc:802] Training of tree  64/300 (tree index:64) done accuracy:0.971774 logloss:0.0816141\n",
      "[INFO 24-01-31 12:18:17.7944 UTC random_forest.cc:802] Training of tree  75/300 (tree index:71) done accuracy:0.971774 logloss:0.0799052\n",
      "[INFO 24-01-31 12:18:17.7948 UTC random_forest.cc:802] Training of tree  87/300 (tree index:86) done accuracy:0.971774 logloss:0.0774856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:17.7951 UTC random_forest.cc:802] Training of tree  97/300 (tree index:96) done accuracy:0.971774 logloss:0.0774835\n",
      "[INFO 24-01-31 12:18:17.7954 UTC random_forest.cc:802] Training of tree  107/300 (tree index:108) done accuracy:0.975806 logloss:0.0744989\n",
      "[INFO 24-01-31 12:18:17.7957 UTC random_forest.cc:802] Training of tree  117/300 (tree index:116) done accuracy:0.975806 logloss:0.0757725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:17.7960 UTC random_forest.cc:802] Training of tree  127/300 (tree index:125) done accuracy:0.979839 logloss:0.0765672\n",
      "[INFO 24-01-31 12:18:17.7964 UTC random_forest.cc:802] Training of tree  138/300 (tree index:138) done accuracy:0.979839 logloss:0.0770547\n",
      "[INFO 24-01-31 12:18:17.7968 UTC random_forest.cc:802] Training of tree  148/300 (tree index:149) done accuracy:0.975806 logloss:0.0774622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:17.7970 UTC random_forest.cc:802] Training of tree  159/300 (tree index:158) done accuracy:0.975806 logloss:0.0782705\n",
      "[INFO 24-01-31 12:18:17.7974 UTC random_forest.cc:802] Training of tree  169/300 (tree index:169) done accuracy:0.975806 logloss:0.0806146\n",
      "[INFO 24-01-31 12:18:17.7978 UTC random_forest.cc:802] Training of tree  180/300 (tree index:178) done accuracy:0.975806 logloss:0.0809432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:17.7983 UTC random_forest.cc:802] Training of tree  196/300 (tree index:193) done accuracy:0.975806 logloss:0.0817119\n",
      "[INFO 24-01-31 12:18:17.7987 UTC random_forest.cc:802] Training of tree  206/300 (tree index:204) done accuracy:0.975806 logloss:0.0811454\n",
      "[INFO 24-01-31 12:18:17.7990 UTC random_forest.cc:802] Training of tree  216/300 (tree index:216) done accuracy:0.975806 logloss:0.0821296\n",
      "[INFO 24-01-31 12:18:17.7993 UTC random_forest.cc:802] Training of tree  226/300 (tree index:223) done accuracy:0.975806 logloss:0.0817466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:17.7996 UTC random_forest.cc:802] Training of tree  237/300 (tree index:237) done accuracy:0.975806 logloss:0.0823455\n",
      "[INFO 24-01-31 12:18:17.7999 UTC random_forest.cc:802] Training of tree  248/300 (tree index:248) done accuracy:0.975806 logloss:0.0824368\n",
      "[INFO 24-01-31 12:18:17.8003 UTC random_forest.cc:802] Training of tree  260/300 (tree index:260) done accuracy:0.971774 logloss:0.0821114\n",
      "[INFO 24-01-31 12:18:17.8006 UTC random_forest.cc:802] Training of tree  270/300 (tree index:271) done accuracy:0.971774 logloss:0.0829068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:17.8010 UTC random_forest.cc:802] Training of tree  281/300 (tree index:279) done accuracy:0.975806 logloss:0.0831618\n",
      "[INFO 24-01-31 12:18:17.8013 UTC random_forest.cc:802] Training of tree  291/300 (tree index:290) done accuracy:0.975806 logloss:0.0826058\n",
      "[INFO 24-01-31 12:18:17.8017 UTC random_forest.cc:802] Training of tree  300/300 (tree index:299) done accuracy:0.975806 logloss:0.0827604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:17.8030 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.975806 logloss:0.0827604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:17.8037 UTC kernel.cc:919] Export model in log directory: /tmpfs/tmp/tmp3eddfnse with prefix dd78f89c05734ab8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:17.8072 UTC kernel.cc:937] Save model in resources\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:17.8101 UTC abstract_model.cc:881] Model self evaluation:\n",
      "Number of predictions (without weights): 248\n",
      "Number of predictions (with weights): 248\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "\n",
      "Accuracy: 0.975806  CI95[W][0.95281 0.989412]\n",
      "LogLoss: : 0.0827604\n",
      "ErrorRate: : 0.0241935\n",
      "\n",
      "Default Accuracy: : 0.451613\n",
      "Default LogLoss: : 1.04913\n",
      "Default ErrorRate: : 0.548387\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "     1   2   3\n",
      "1  110   1   1\n",
      "2    0  86   0\n",
      "3    4   0  46\n",
      "Total: 248\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:17.8203 UTC kernel.cc:1233] Loading model from path /tmpfs/tmp/tmp3eddfnse/model/ with prefix dd78f89c05734ab8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:17.8331 UTC decision_forest.cc:660] Model loaded with 300 root(s), 4152 node(s), and 7 input feature(s).\n",
      "[INFO 24-01-31 12:18:17.8332 UTC abstract_model.cc:1344] Engine \"RandomForestGeneric\" built\n",
      "[INFO 24-01-31 12:18:17.8332 UTC kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.055359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7fe5fc1edc10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%set_cell_height 300\n",
    "\n",
    "# Specify the model.\n",
    "model_1 = tfdf.keras.RandomForestModel(verbose=2)\n",
    "\n",
    "# Train the model.\n",
    "model_1.fit(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBnjxdip-MC0"
   },
   "source": [
    "### Remarks\n",
    "\n",
    "-   No input features are specified. Therefore, all the columns will be used as\n",
    "    input features except for the label. The feature used by the model are shown\n",
    "    in the training logs and in the `model.summary()`.\n",
    "-   DFs consume natively numerical, categorical, categorical-set features and\n",
    "    missing-values. Numerical features do not need to be normalized. Categorical\n",
    "    string values do not need to be encoded in a dictionary.\n",
    "-   No training hyper-parameters are specified. Therefore the default\n",
    "    hyper-parameters will be used. Default hyper-parameters provide\n",
    "    reasonable results in most situations.\n",
    "-   Calling `compile` on the model before the `fit` is optional. Compile can be\n",
    "    used to provide extra evaluation metrics.\n",
    "-   Training algorithms do not need validation datasets. If a validation dataset\n",
    "    is provided, it will only be used to show metrics.\n",
    "-   Tweak the `verbose` argument to `RandomForestModel` to control the amount of\n",
    "    displayed training logs. Set `verbose=0` to hide most of the logs. Set\n",
    "    `verbose=2` to show all the logs.\n",
    "\n",
    "**Note:** A *Categorical-Set* feature is composed of a set of categorical values (while a *Categorical* is only one value). More details and examples are given later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSdtNJUArBpl"
   },
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Udtu_uS1paSu"
   },
   "source": [
    "Let's evaluate our model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xUy4ULEMtDXB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0000e+00 - accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss: 0.0000\n",
      "accuracy: 0.9688\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(metrics=[\"accuracy\"])\n",
    "evaluation = model_1.evaluate(test_ds, return_dict=True)\n",
    "print()\n",
    "\n",
    "for name, value in evaluation.items():\n",
    "  print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tlhfzZ34pfO4"
   },
   "source": [
    "**Remark:** The test accuracy is close to the Out-of-bag accuracy\n",
    "shown in the training logs.\n",
    "\n",
    "See the **Model Self Evaluation** section below for more evaluation methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHBFtUeElRYz"
   },
   "source": [
    "## Prepare this model for TensorFlow Serving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbC4lmgfr5Sm"
   },
   "source": [
    "Export the model to the SavedModel format for later re-use e.g.\n",
    "[TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08YWGr9U2fza"
   },
   "outputs": [],
   "source": [
    "model_1.save(\"/tmp/my_saved_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-8R02_SXpbq"
   },
   "source": [
    "## Plot the model\n",
    "\n",
    "Plotting a decision tree and following the first branches helps learning about decision forests. In some cases, plotting a model can even be used for debugging.\n",
    "\n",
    "Because of the difference in the way they are trained, some models are more interesting to plan than others. Because of the noise injected during training and the depth of the trees, plotting Random Forest is less informative than plotting a CART or the first tree of a Gradient Boosted Tree.\n",
    "\n",
    "Never the less, let's plot the first tree of our Random Forest model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUIxf8N6Yjl0"
   },
   "outputs": [],
   "source": [
    "tfdf.model_plotter.plot_model_in_colab(model_1, tree_idx=0, max_depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPcL_hDnY7Zy"
   },
   "source": [
    "The root node on the left contains the first condition (`bill_depth_mm >= 16.55`), number of examples (240) and label distribution (the red-blue-green bar).\n",
    "\n",
    "Examples that evaluates true to `bill_depth_mm >= 16.55` are branched to the green path. The other ones are branched to the red path.\n",
    "\n",
    "The deeper the node, the more `pure` they become i.e. the label distribution is biased toward a subset of classes. \n",
    "\n",
    "**Note:** Over the mouse on top of the plot for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ob3ovQ2seVY"
   },
   "source": [
    "## Model structure and feature importance\n",
    "\n",
    "The overall structure of the model is show with `.summary()`. You will see:\n",
    "\n",
    "-   **Type**: The learning algorithm used to train the model (`Random Forest` in\n",
    "    our case).\n",
    "-   **Task**: The problem solved by the model (`Classification` in our case).\n",
    "-   **Input Features**: The input features of the model.\n",
    "-   **Variable Importance**: Different measures of the importance of each\n",
    "    feature for the model.\n",
    "-   **Out-of-bag evaluation**: The out-of-bag evaluation of the model. This is a\n",
    "    cheap and efficient alternative to cross-validation.\n",
    "-   **Number of {trees, nodes} and other metrics**: Statistics about the\n",
    "    structure of the decisions forests.\n",
    "\n",
    "**Remark:** The summary's content depends on the learning algorithm (e.g.\n",
    "Out-of-bag is only available for Random Forest) and the hyper-parameters (e.g.\n",
    "the *mean-decrease-in-accuracy* variable importance can be disabled in the\n",
    "hyper-parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzXME28Lq7Il"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 1 (1.00 Byte)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 0 (0.00 Byte)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 1 (1.00 Byte)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: \"RANDOM_FOREST\"\n",
      "Task: CLASSIFICATION\n",
      "Label: \"__LABEL\"\n",
      "\n",
      "Input Features (7):\n",
      "\tbill_depth_mm\n",
      "\tbill_length_mm\n",
      "\tbody_mass_g\n",
      "\tflipper_length_mm\n",
      "\tisland\n",
      "\tsex\n",
      "\tyear\n",
      "\n",
      "No weights\n",
      "\n",
      "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
      "    1.    \"bill_length_mm\"  0.484952 ################\n",
      "    2. \"flipper_length_mm\"  0.404391 ##########\n",
      "    3.     \"bill_depth_mm\"  0.324956 #####\n",
      "    4.            \"island\"  0.300894 ###\n",
      "    5.       \"body_mass_g\"  0.272408 #\n",
      "    6.               \"sex\"  0.245202 \n",
      "    7.              \"year\"  0.243988 \n",
      "\n",
      "Variable Importance: NUM_AS_ROOT:\n",
      "    1. \"flipper_length_mm\" 125.000000 ################\n",
      "    2.    \"bill_length_mm\" 116.000000 ##############\n",
      "    3.     \"bill_depth_mm\" 47.000000 #####\n",
      "    4.       \"body_mass_g\"  6.000000 \n",
      "    5.            \"island\"  6.000000 \n",
      "\n",
      "Variable Importance: NUM_NODES:\n",
      "    1.    \"bill_length_mm\" 676.000000 ################\n",
      "    2.     \"bill_depth_mm\" 397.000000 #########\n",
      "    3. \"flipper_length_mm\" 308.000000 #######\n",
      "    4.       \"body_mass_g\" 254.000000 #####\n",
      "    5.            \"island\" 252.000000 #####\n",
      "    6.               \"sex\" 24.000000 \n",
      "    7.              \"year\" 15.000000 \n",
      "\n",
      "Variable Importance: SUM_SCORE:\n",
      "    1.    \"bill_length_mm\" 30518.214361 ################\n",
      "    2. \"flipper_length_mm\" 20495.037155 ##########\n",
      "    3.            \"island\" 10912.604448 #####\n",
      "    4.     \"bill_depth_mm\" 10432.806229 #####\n",
      "    5.       \"body_mass_g\" 2345.918166 #\n",
      "    6.               \"sex\" 166.745558 \n",
      "    7.              \"year\" 25.203954 \n",
      "\n",
      "\n",
      "\n",
      "Winner takes all: true\n",
      "Out-of-bag evaluation: accuracy:0.975806 logloss:0.0827604\n",
      "Number of trees: 300\n",
      "Total number of nodes: 4152\n",
      "\n",
      "Number of nodes by tree:\n",
      "Count: 300 Average: 13.84 StdDev: 2.98235\n",
      "Min: 7 Max: 23 Ignored: 0\n",
      "----------------------------------------------\n",
      "[  7,  8)  2   0.67%   0.67%\n",
      "[  8,  9)  0   0.00%   0.67%\n",
      "[  9, 10) 24   8.00%   8.67% ###\n",
      "[ 10, 11)  0   0.00%   8.67%\n",
      "[ 11, 12) 62  20.67%  29.33% ########\n",
      "[ 12, 13)  0   0.00%  29.33%\n",
      "[ 13, 14) 75  25.00%  54.33% ##########\n",
      "[ 14, 15)  0   0.00%  54.33%\n",
      "[ 15, 16) 67  22.33%  76.67% #########\n",
      "[ 16, 17)  0   0.00%  76.67%\n",
      "[ 17, 18) 43  14.33%  91.00% ######\n",
      "[ 18, 19)  0   0.00%  91.00%\n",
      "[ 19, 20) 22   7.33%  98.33% ###\n",
      "[ 20, 21)  0   0.00%  98.33%\n",
      "[ 21, 22)  2   0.67%  99.00%\n",
      "[ 22, 23)  0   0.00%  99.00%\n",
      "[ 23, 23]  3   1.00% 100.00%\n",
      "\n",
      "Depth by leafs:\n",
      "Count: 2226 Average: 3.18553 StdDev: 0.963012\n",
      "Min: 1 Max: 6 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 1, 2)  16   0.72%   0.72%\n",
      "[ 2, 3) 584  26.24%  26.95% #######\n",
      "[ 3, 4) 817  36.70%  63.66% ##########\n",
      "[ 4, 5) 601  27.00%  90.66% #######\n",
      "[ 5, 6) 196   8.81%  99.46% ##\n",
      "[ 6, 6]  12   0.54% 100.00%\n",
      "\n",
      "Number of training obs by leaf:\n",
      "Count: 2226 Average: 33.4232 StdDev: 33.4752\n",
      "Min: 5 Max: 121 Ignored: 0\n",
      "----------------------------------------------\n",
      "[   5,  10) 1037  46.59%  46.59% ##########\n",
      "[  10,  16)  112   5.03%  51.62% #\n",
      "[  16,  22)   73   3.28%  54.90% #\n",
      "[  22,  28)   70   3.14%  58.04% #\n",
      "[  28,  34)   73   3.28%  61.32% #\n",
      "[  34,  40)   76   3.41%  64.73% #\n",
      "[  40,  45)  100   4.49%  69.23% #\n",
      "[  45,  51)   63   2.83%  72.06% #\n",
      "[  51,  57)   30   1.35%  73.41%\n",
      "[  57,  63)   26   1.17%  74.57%\n",
      "[  63,  69)   33   1.48%  76.06%\n",
      "[  69,  75)   71   3.19%  79.25% #\n",
      "[  75,  81)   96   4.31%  83.56% #\n",
      "[  81,  86)  102   4.58%  88.14% #\n",
      "[  86,  92)  111   4.99%  93.13% #\n",
      "[  92,  98)   73   3.28%  96.41% #\n",
      "[  98, 104)   38   1.71%  98.11%\n",
      "[ 104, 110)   27   1.21%  99.33%\n",
      "[ 110, 116)   10   0.45%  99.78%\n",
      "[ 116, 121]    5   0.22% 100.00%\n",
      "\n",
      "Attribute in nodes:\n",
      "\t676 : bill_length_mm [NUMERICAL]\n",
      "\t397 : bill_depth_mm [NUMERICAL]\n",
      "\t308 : flipper_length_mm [NUMERICAL]\n",
      "\t254 : body_mass_g [NUMERICAL]\n",
      "\t252 : island [CATEGORICAL]\n",
      "\t24 : sex [CATEGORICAL]\n",
      "\t15 : year [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 0:\n",
      "\t125 : flipper_length_mm [NUMERICAL]\n",
      "\t116 : bill_length_mm [NUMERICAL]\n",
      "\t47 : bill_depth_mm [NUMERICAL]\n",
      "\t6 : island [CATEGORICAL]\n",
      "\t6 : body_mass_g [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 1:\n",
      "\t265 : bill_length_mm [NUMERICAL]\n",
      "\t200 : flipper_length_mm [NUMERICAL]\n",
      "\t187 : bill_depth_mm [NUMERICAL]\n",
      "\t168 : island [CATEGORICAL]\n",
      "\t64 : body_mass_g [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 2:\n",
      "\t469 : bill_length_mm [NUMERICAL]\n",
      "\t319 : bill_depth_mm [NUMERICAL]\n",
      "\t265 : flipper_length_mm [NUMERICAL]\n",
      "\t227 : island [CATEGORICAL]\n",
      "\t171 : body_mass_g [NUMERICAL]\n",
      "\t14 : sex [CATEGORICAL]\n",
      "\t3 : year [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 3:\n",
      "\t633 : bill_length_mm [NUMERICAL]\n",
      "\t380 : bill_depth_mm [NUMERICAL]\n",
      "\t296 : flipper_length_mm [NUMERICAL]\n",
      "\t251 : island [CATEGORICAL]\n",
      "\t231 : body_mass_g [NUMERICAL]\n",
      "\t20 : sex [CATEGORICAL]\n",
      "\t8 : year [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 5:\n",
      "\t676 : bill_length_mm [NUMERICAL]\n",
      "\t397 : bill_depth_mm [NUMERICAL]\n",
      "\t308 : flipper_length_mm [NUMERICAL]\n",
      "\t254 : body_mass_g [NUMERICAL]\n",
      "\t252 : island [CATEGORICAL]\n",
      "\t24 : sex [CATEGORICAL]\n",
      "\t15 : year [NUMERICAL]\n",
      "\n",
      "Condition type in nodes:\n",
      "\t1650 : HigherCondition\n",
      "\t276 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 0:\n",
      "\t294 : HigherCondition\n",
      "\t6 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 1:\n",
      "\t716 : HigherCondition\n",
      "\t168 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 2:\n",
      "\t1227 : HigherCondition\n",
      "\t241 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 3:\n",
      "\t1548 : HigherCondition\n",
      "\t271 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 5:\n",
      "\t1650 : HigherCondition\n",
      "\t276 : ContainsBitmapCondition\n",
      "Node format: NOT_SET\n",
      "\n",
      "Training OOB:\n",
      "\ttrees: 1, Out-of-bag evaluation: accuracy:0.952941 logloss:1.69617\n",
      "\ttrees: 11, Out-of-bag evaluation: accuracy:0.961864 logloss:0.671715\n",
      "\ttrees: 21, Out-of-bag evaluation: accuracy:0.967078 logloss:0.503792\n",
      "\ttrees: 31, Out-of-bag evaluation: accuracy:0.971774 logloss:0.219305\n",
      "\ttrees: 42, Out-of-bag evaluation: accuracy:0.967742 logloss:0.0889185\n",
      "\ttrees: 53, Out-of-bag evaluation: accuracy:0.967742 logloss:0.0857322\n",
      "\ttrees: 64, Out-of-bag evaluation: accuracy:0.971774 logloss:0.0816141\n",
      "\ttrees: 75, Out-of-bag evaluation: accuracy:0.971774 logloss:0.0799052\n",
      "\ttrees: 87, Out-of-bag evaluation: accuracy:0.971774 logloss:0.0774856\n",
      "\ttrees: 97, Out-of-bag evaluation: accuracy:0.971774 logloss:0.0774835\n",
      "\ttrees: 107, Out-of-bag evaluation: accuracy:0.975806 logloss:0.0744989\n",
      "\ttrees: 117, Out-of-bag evaluation: accuracy:0.975806 logloss:0.0757725\n",
      "\ttrees: 127, Out-of-bag evaluation: accuracy:0.979839 logloss:0.0765672\n",
      "\ttrees: 138, Out-of-bag evaluation: accuracy:0.979839 logloss:0.0770547\n",
      "\ttrees: 148, Out-of-bag evaluation: accuracy:0.975806 logloss:0.0774622\n",
      "\ttrees: 159, Out-of-bag evaluation: accuracy:0.975806 logloss:0.0782705\n",
      "\ttrees: 169, Out-of-bag evaluation: accuracy:0.975806 logloss:0.0806146\n",
      "\ttrees: 180, Out-of-bag evaluation: accuracy:0.975806 logloss:0.0809432\n",
      "\ttrees: 196, Out-of-bag evaluation: accuracy:0.975806 logloss:0.0817119\n",
      "\ttrees: 206, Out-of-bag evaluation: accuracy:0.975806 logloss:0.0811454\n",
      "\ttrees: 216, Out-of-bag evaluation: accuracy:0.975806 logloss:0.0821296\n",
      "\ttrees: 226, Out-of-bag evaluation: accuracy:0.975806 logloss:0.0817466\n",
      "\ttrees: 237, Out-of-bag evaluation: accuracy:0.975806 logloss:0.0823455\n",
      "\ttrees: 248, Out-of-bag evaluation: accuracy:0.975806 logloss:0.0824368\n",
      "\ttrees: 260, Out-of-bag evaluation: accuracy:0.971774 logloss:0.0821114\n",
      "\ttrees: 270, Out-of-bag evaluation: accuracy:0.971774 logloss:0.0829068\n",
      "\ttrees: 281, Out-of-bag evaluation: accuracy:0.975806 logloss:0.0831618\n",
      "\ttrees: 291, Out-of-bag evaluation: accuracy:0.975806 logloss:0.0826058\n",
      "\ttrees: 300, Out-of-bag evaluation: accuracy:0.975806 logloss:0.0827604\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%set_cell_height 300\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4ApRpUm02zU"
   },
   "source": [
    "The information in ``summary`` are all available programmatically using the model inspector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3xuB3jN1Cww"
   },
   "outputs": [],
   "source": [
    "# The input features\n",
    "model_1.make_inspector().features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZ2RBbU51L6s"
   },
   "outputs": [],
   "source": [
    "# The feature importances\n",
    "model_1.make_inspector().variable_importances()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zvyRJVk1aEk"
   },
   "source": [
    "The content of the summary and the inspector depends on the learning algorithm (`tfdf.keras.RandomForestModel` in this case) and its hyper-parameters (e.g. `compute_oob_variable_importances=True` will trigger the computation of Out-of-bag variable importances for the Random Forest learner)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFVmrHtWXYKY"
   },
   "source": [
    "## Model Self Evaluation\n",
    "\n",
    "During training TFDF models can self evaluate even if no validation dataset is provided to the `fit()` method. The exact logic depends on the model. For example, Random Forest will use Out-of-bag evaluation while Gradient Boosted Trees will use internal train-validation.\n",
    "\n",
    "**Note:** While this evaluation is  computed during training, it is NOT computed on the training dataset and can be used as a low quality evaluation.\n",
    "\n",
    "The model self evaluation is available with the inspector's `evaluation()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZPzyIMmYmsI"
   },
   "outputs": [],
   "source": [
    "model_1.make_inspector().evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBSz-jE0Qss_"
   },
   "source": [
    "## Plotting the training logs\n",
    "\n",
    "The training logs show the quality of the model (e.g. accuracy evaluated on the out-of-bag or validation dataset) according to the number of trees in the model. These logs are helpful to study the balance between model size and model quality.\n",
    "\n",
    "The logs are available in multiple ways:\n",
    "\n",
    "1. Displayed in during training if `fit()` is wrapped in `with sys_pipes():` (see example above).\n",
    "1. At the end of the model summary i.e. `model.summary()` (see example above).\n",
    "1. Programmatically, using the model inspector i.e. `model.make_inspector().training_logs()`.\n",
    "1. Using [TensorBoard](https://www.tensorflow.org/tensorboard)\n",
    "\n",
    "Let's try the options 2 and 3:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbRk7xvpTKQG"
   },
   "outputs": [],
   "source": [
    "%set_cell_height 150\n",
    "model_1.make_inspector().training_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WynFJCEbhuF_"
   },
   "source": [
    "Let's plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzPH7Gggh0g1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logs = model_1.make_inspector().training_logs()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Accuracy (out-of-bag)\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs])\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Logloss (out-of-bag)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1xzugBRhwuN"
   },
   "source": [
    "This dataset is small. You can see the model converging almost immediately.\n",
    "\n",
    "Let's use TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5R_m-JmvU9tu"
   },
   "outputs": [],
   "source": [
    "# This cell start TensorBoard that can be slow.\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "# Google internal version\n",
    "# %load_ext google3.learning.brain.tensorboard.notebook.extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j6mp7K6HWwqQ"
   },
   "outputs": [],
   "source": [
    "# Clear existing results (if any)\n",
    "!rm -fr \"/tmp/tensorboard_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16NbLILYo124"
   },
   "outputs": [],
   "source": [
    "# Export the meta-data to tensorboard.\n",
    "model_1.make_inspector().export_to_tensorboard(\"/tmp/tensorboard_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TSsN6aTXW0LJ"
   },
   "outputs": [],
   "source": [
    "# docs_infra: no_execute\n",
    "# Start a tensorboard instance.\n",
    "%tensorboard --logdir \"/tmp/tensorboard_logs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_tlSccjZ8kE"
   },
   "source": [
    "<!-- <img class=\"tfo-display-only-on-site\" src=\"images/beginner_tensorboard.png\"/> -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phTUr6F1t-_E"
   },
   "source": [
    "## Re-train the model with a different learning algorithm\n",
    "\n",
    "The learning algorithm is defined by the model class. For\n",
    "example, `tfdf.keras.RandomForestModel()` trains a Random Forest, while\n",
    "`tfdf.keras.GradientBoostedTreesModel()` trains a Gradient Boosted Decision\n",
    "Trees.\n",
    "\n",
    "The learning algorithms are listed by calling `tfdf.keras.get_all_models()` or in the\n",
    "[learner list](https://ydf.readthedocs.io/en/latest/cli_user_manual.html#learners-and-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwEAAzUZq2m8"
   },
   "outputs": [],
   "source": [
    "tfdf.keras.get_all_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmzvuI78voD4"
   },
   "source": [
    "The description of the learning algorithms and their hyper-parameters are also available in the [API reference](https://www.tensorflow.org/decision_forests/api_docs/python/tfdf) and builtin help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hONToBav4DE"
   },
   "outputs": [],
   "source": [
    "# help works anywhere.\n",
    "help(tfdf.keras.RandomForestModel)\n",
    "\n",
    "# ? only works in ipython or notebooks, it usually opens on a separate panel.\n",
    "tfdf.keras.RandomForestModel?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuWEYvXaiwhk"
   },
   "source": [
    "## Using a subset of features\n",
    "\n",
    "The previous example did not specify the features, so all the columns were used\n",
    "as input feature (except for the label). The following example shows how to\n",
    "specify input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgn_LnRz3M7z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num validation examples: tf.Tensor(96, shape=(), dtype=int32)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset read in 0:00:00.202614. Found 96 examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.239200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:27.9538 UTC kernel.cc:1233] Loading model from path /tmpfs/tmp/tmpp64xoosr/model/ with prefix 3b3b3b2760024850\n",
      "[INFO 24-01-31 12:18:27.9584 UTC decision_forest.cc:660] Model loaded with 51 root(s), 1589 node(s), and 2 input feature(s).\n",
      "[INFO 24-01-31 12:18:27.9584 UTC abstract_model.cc:1344] Engine \"GradientBoostedTreesGeneric\" built\n",
      "[INFO 24-01-31 12:18:27.9584 UTC kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.9271"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0000e+00 - accuracy: 0.9271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'accuracy': 0.9270833134651184}\n"
     ]
    }
   ],
   "source": [
    "feature_1 = tfdf.keras.FeatureUsage(name=\"bill_length_mm\")\n",
    "feature_2 = tfdf.keras.FeatureUsage(name=\"island\")\n",
    "\n",
    "all_features = [feature_1, feature_2]\n",
    "\n",
    "# Note: This model is only trained with two features. It will not be as good as\n",
    "# the one trained on all features.\n",
    "\n",
    "model_2 = tfdf.keras.GradientBoostedTreesModel(\n",
    "    features=all_features, exclude_non_specified_features=True)\n",
    "\n",
    "model_2.compile(metrics=[\"accuracy\"])\n",
    "model_2.fit(train_ds, validation_data=test_ds)\n",
    "\n",
    "print(model_2.evaluate(test_ds, return_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvM84cgCmbUR"
   },
   "source": [
    "**Note:** As expected, the accuracy is lower than previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFmqpivc7x7p"
   },
   "source": [
    "**TF-DF** attaches a **semantics** to each feature. This semantics controls how\n",
    "the feature is used by the model. The following semantics are currently supported:\n",
    "\n",
    "-   **Numerical**: Generally for quantities or counts with full ordering. For\n",
    "    example, the age of a person, or the number of items in a bag. Can be a\n",
    "    float or an integer. Missing values are represented with float(Nan) or with\n",
    "    an empty sparse tensor.\n",
    "-   **Categorical**: Generally for a type/class in finite set of possible values\n",
    "    without ordering. For example, the color RED in the set {RED, BLUE, GREEN}.\n",
    "    Can be a string or an integer. Missing values are represented as \"\" (empty\n",
    "    sting), value -2 or with an empty sparse tensor.\n",
    "-   **Categorical-Set**: A set of categorical values. Great to represent\n",
    "    tokenized text. Can be a string or an integer in a sparse tensor or a\n",
    "    ragged tensor (recommended). The order/index of each item doesn't matter.\n",
    "\n",
    "If not specified, the semantics is inferred from the representation type and shown in the training logs:\n",
    "\n",
    "- int, float (dense or sparse) → Numerical semantics.\n",
    "- str (dense or sparse) → Categorical semantics\n",
    "- int, str (ragged) → Categorical-Set semantics\n",
    "\n",
    "In some cases, the inferred semantics is incorrect. For example: An Enum stored as an integer is semantically categorical, but it will be detected as numerical. In this case, you should specify the semantic argument in the input. The `education_num` field of the Adult dataset is classical example.\n",
    "\n",
    "This dataset doesn't contain such a feature. However, for the demonstration, we will make the model treat the `year` as a categorical feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNRIwLYC8zrp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num validation examples: tf.Tensor(96, shape=(), dtype=int32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset read in 0:00:00.154900. Found 96 examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.213496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:28.9470 UTC kernel.cc:1233] Loading model from path /tmpfs/tmp/tmpdtv_ods_/model/ with prefix 67767722bfd0419b\n",
      "[INFO 24-01-31 12:18:28.9508 UTC decision_forest.cc:660] Model loaded with 33 root(s), 1003 node(s), and 3 input feature(s).\n",
      "[INFO 24-01-31 12:18:28.9509 UTC kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7fe42066b9a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%set_cell_height 300\n",
    "\n",
    "feature_1 = tfdf.keras.FeatureUsage(name=\"year\", semantic=tfdf.keras.FeatureSemantic.CATEGORICAL)\n",
    "feature_2 = tfdf.keras.FeatureUsage(name=\"bill_length_mm\")\n",
    "feature_3 = tfdf.keras.FeatureUsage(name=\"sex\")\n",
    "all_features = [feature_1, feature_2, feature_3]\n",
    "\n",
    "model_3 = tfdf.keras.GradientBoostedTreesModel(features=all_features, exclude_non_specified_features=True)\n",
    "model_3.compile( metrics=[\"accuracy\"])\n",
    "\n",
    "model_3.fit(train_ds, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AQaNwihcpP7"
   },
   "source": [
    "Note that `year` is in the list of CATEGORICAL features (unlike the first run)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYrw7nKN40Vm"
   },
   "source": [
    "## Hyper-parameters\n",
    "\n",
    "**Hyper-parameters** are parameters of the training algorithm that impact\n",
    "the quality of the final model. They are specified in the model class\n",
    "constructor. The list of hyper-parameters is visible with the *question mark* colab command (e.g. `?tfdf.keras.GradientBoostedTreesModel`).\n",
    "\n",
    "Alternatively, you can find them on the [TensorFlow Decision Forest Github](https://github.com/tensorflow/decision-forests/blob/main/tensorflow_decision_forests/keras/wrappers_pre_generated.py) or the [Yggdrasil Decision Forest documentation](https://github.com/google/yggdrasil-decision-forests/blob/main/documentation/learners.md).\n",
    "\n",
    "The default hyper-parameters of each algorithm matches approximatively the initial publication paper. To ensure consistancy, new features and their matching hyper-parameters are always disable by default. That's why it is a good idea to tune your hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vHgPr4Pt43hv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.563517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:30.0216 UTC kernel.cc:1233] Loading model from path /tmpfs/tmp/tmpjgzlsodc/model/ with prefix dc1054235a75450b\n",
      "[INFO 24-01-31 12:18:30.0383 UTC decision_forest.cc:660] Model loaded with 108 root(s), 5406 node(s), and 7 input feature(s).\n",
      "[INFO 24-01-31 12:18:30.0384 UTC kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7fe420554be0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A classical but slighly more complex model.\n",
    "model_6 = tfdf.keras.GradientBoostedTreesModel(\n",
    "    num_trees=500, growing_strategy=\"BEST_FIRST_GLOBAL\", max_depth=8)\n",
    "model_6.fit(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uECgPGDc2P4p"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x7fe4204c8e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7fe42056b610>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A more complex, but possibly, more accurate model.\n",
    "model_7 = tfdf.keras.GradientBoostedTreesModel(\n",
    "    num_trees=500,\n",
    "    growing_strategy=\"BEST_FIRST_GLOBAL\",\n",
    "    max_depth=8,\n",
    "    split_axis=\"SPARSE_OBLIQUE\",\n",
    "    categorical_algorithm=\"RANDOM\",\n",
    "    )\n",
    "model_7.fit(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xk7wEmUZu3V0"
   },
   "source": [
    "As new training methods are published and implemented, combination of hyper-parameters can emerge as good or almost-always-better than the default parameters. To avoid changing the default hyper-parameter values these good combination are indexed and available as hyper-parameter templates.\n",
    "\n",
    "For example, the `benchmark_rank1` template is the best combination on our internal benchmarks. Those templates are versioned to allow training configuration stability e.g. `benchmark_rank1@v1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LtrRhMhj3hSu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:42.2478 UTC kernel.cc:1233] Loading model from path /tmpfs/tmp/tmpivrthe03/model/ with prefix 3f17958e0d434c5e\n",
      "[INFO 24-01-31 12:18:42.3573 UTC decision_forest.cc:660] Model loaded with 900 root(s), 37318 node(s), and 7 input feature(s).\n",
      "[INFO 24-01-31 12:18:42.3573 UTC kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x7fe420550280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x7fe420550280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7fe42040bc70>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A good template of hyper-parameters.\n",
    "model_8 = tfdf.keras.GradientBoostedTreesModel(hyperparameter_template=\"benchmark_rank1\")\n",
    "model_8.fit(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSDXcKXB3u6M"
   },
   "source": [
    "The available templates are available with `predefined_hyperparameters`. Note that different learning algorithms have different templates, even if the name is similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQrWI2iv37Bo"
   },
   "outputs": [],
   "source": [
    "# The hyper-parameter templates of the Gradient Boosted Tree model.\n",
    "print(tfdf.keras.GradientBoostedTreesModel.predefined_hyperparameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcX4tov1_lwp"
   },
   "source": [
    "## Feature Preprocessing\n",
    "\n",
    "Pre-processing features is sometimes necessary to consume signals with complex\n",
    "structures, to regularize the model or to apply transfer learning.\n",
    "Pre-processing can be done in one of three ways:\n",
    "\n",
    "1.  Preprocessing on the Pandas dataframe. This solution is easy to implement\n",
    "    and generally suitable for experimentation. However, the\n",
    "    pre-processing logic will not be exported in the model by `model.save()`.\n",
    "\n",
    "2.  [Keras Preprocessing](https://keras.io/guides/preprocessing_layers/): While\n",
    "    more complex than the previous solution, Keras Preprocessing is packaged in\n",
    "    the model.\n",
    "\n",
    "3.  [TensorFlow Feature Columns](https://www.tensorflow.org/tutorials/structured_data/feature_columns):\n",
    "    This API is part of the TF Estimator library (!= Keras) and planned for\n",
    "    deprecation. This solution is interesting when using existing preprocessing\n",
    "    code.\n",
    "\n",
    "Note: Using [TensorFlow Hub](https://www.tensorflow.org/hub)\n",
    "pre-trained embedding is often, a great way to consume text and image with\n",
    "TF-DF. For example, `hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\")`. See the [Intermediate tutorial](intermediate_colab.ipynb) for more details.\n",
    "\n",
    "In the next example, pre-process the `body_mass_g` feature into `body_mass_kg = body_mass_g / 1000`. The `bill_length_mm` is consumed without pre-processing. Note that such\n",
    "monotonic transformations have generally no impact on decision forest models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tGcIvTeKAApp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.041472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x7fe420277af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:43.8764 UTC kernel.cc:1233] Loading model from path /tmpfs/tmp/tmpg1pw2xd5/model/ with prefix 04ad7ce2517f4691\n",
      "[INFO 24-01-31 12:18:43.8929 UTC decision_forest.cc:660] Model loaded with 300 root(s), 5644 node(s), and 2 input feature(s).\n",
      "[INFO 24-01-31 12:18:43.8929 UTC kernel.cc:1061] Use fast generic engine\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x7fe420277af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"random_forest_model_1\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " model (Functional)          {'body_mass_kg': (None,   0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              1),                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              'bill_length_mm': (Non             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             e, 1)}                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 1 (1.00 Byte)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 0 (0.00 Byte)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 1 (1.00 Byte)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: \"RANDOM_FOREST\"\n",
      "Task: CLASSIFICATION\n",
      "Label: \"__LABEL\"\n",
      "\n",
      "Input Features (2):\n",
      "\tbill_length_mm\n",
      "\tbody_mass_kg\n",
      "\n",
      "No weights\n",
      "\n",
      "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
      "    1. \"bill_length_mm\"  0.996678 ################\n",
      "    2.   \"body_mass_kg\"  0.412305 \n",
      "\n",
      "Variable Importance: NUM_AS_ROOT:\n",
      "    1. \"bill_length_mm\" 299.000000 ################\n",
      "    2.   \"body_mass_kg\"  1.000000 \n",
      "\n",
      "Variable Importance: NUM_NODES:\n",
      "    1. \"bill_length_mm\" 1415.000000 ################\n",
      "    2.   \"body_mass_kg\" 1257.000000 \n",
      "\n",
      "Variable Importance: SUM_SCORE:\n",
      "    1. \"bill_length_mm\" 48426.479070 ################\n",
      "    2.   \"body_mass_kg\" 24452.918388 \n",
      "\n",
      "\n",
      "\n",
      "Winner takes all: true\n",
      "Out-of-bag evaluation: accuracy:0.927419 logloss:0.571626\n",
      "Number of trees: 300\n",
      "Total number of nodes: 5644\n",
      "\n",
      "Number of nodes by tree:\n",
      "Count: 300 Average: 18.8133 StdDev: 2.91979\n",
      "Min: 11 Max: 29 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 11, 12)  2   0.67%   0.67%\n",
      "[ 12, 13)  0   0.00%   0.67%\n",
      "[ 13, 14) 10   3.33%   4.00% #\n",
      "[ 14, 15)  0   0.00%   4.00%\n",
      "[ 15, 16) 36  12.00%  16.00% ####\n",
      "[ 16, 17)  0   0.00%  16.00%\n",
      "[ 17, 18) 73  24.33%  40.33% #########\n",
      "[ 18, 19)  0   0.00%  40.33%\n",
      "[ 19, 20) 81  27.00%  67.33% ##########\n",
      "[ 20, 21)  0   0.00%  67.33%\n",
      "[ 21, 22) 54  18.00%  85.33% #######\n",
      "[ 22, 23)  0   0.00%  85.33%\n",
      "[ 23, 24) 34  11.33%  96.67% ####\n",
      "[ 24, 25)  0   0.00%  96.67%\n",
      "[ 25, 26)  8   2.67%  99.33% #\n",
      "[ 26, 27)  0   0.00%  99.33%\n",
      "[ 27, 28)  1   0.33%  99.67%\n",
      "[ 28, 29)  0   0.00%  99.67%\n",
      "[ 29, 29]  1   0.33% 100.00%\n",
      "\n",
      "Depth by leafs:\n",
      "Count: 2972 Average: 3.60902 StdDev: 0.94029\n",
      "Min: 1 Max: 7 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 1, 2)   22   0.74%   0.74%\n",
      "[ 2, 3)  300  10.09%  10.83% ###\n",
      "[ 3, 4) 1017  34.22%  45.05% #########\n",
      "[ 4, 5) 1179  39.67%  84.72% ##########\n",
      "[ 5, 6)  393  13.22%  97.95% ###\n",
      "[ 6, 7)   55   1.85%  99.80%\n",
      "[ 7, 7]    6   0.20% 100.00%\n",
      "\n",
      "Number of training obs by leaf:\n",
      "Count: 2972 Average: 25.0336 StdDev: 29.7355\n",
      "Min: 5 Max: 121 Ignored: 0\n",
      "----------------------------------------------\n",
      "[   5,  10) 1766  59.42%  59.42% ##########\n",
      "[  10,  16)  211   7.10%  66.52% #\n",
      "[  16,  22)   55   1.85%  68.37%\n",
      "[  22,  28)   50   1.68%  70.05%\n",
      "[  28,  34)   65   2.19%  72.24%\n",
      "[  34,  40)  109   3.67%  75.91% #\n",
      "[  40,  45)   70   2.36%  78.26%\n",
      "[  45,  51)   43   1.45%  79.71%\n",
      "[  51,  57)   48   1.62%  81.33%\n",
      "[  57,  63)   60   2.02%  83.34%\n",
      "[  63,  69)   63   2.12%  85.46%\n",
      "[  69,  75)   87   2.93%  88.39%\n",
      "[  75,  81)   65   2.19%  90.58%\n",
      "[  81,  86)   53   1.78%  92.36%\n",
      "[  86,  92)   74   2.49%  94.85%\n",
      "[  92,  98)   74   2.49%  97.34%\n",
      "[  98, 104)   42   1.41%  98.76%\n",
      "[ 104, 110)   24   0.81%  99.56%\n",
      "[ 110, 116)   11   0.37%  99.93%\n",
      "[ 116, 121]    2   0.07% 100.00%\n",
      "\n",
      "Attribute in nodes:\n",
      "\t1415 : bill_length_mm [NUMERICAL]\n",
      "\t1257 : body_mass_kg [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 0:\n",
      "\t299 : bill_length_mm [NUMERICAL]\n",
      "\t1 : body_mass_kg [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 1:\n",
      "\t559 : bill_length_mm [NUMERICAL]\n",
      "\t319 : body_mass_kg [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 2:\n",
      "\t949 : bill_length_mm [NUMERICAL]\n",
      "\t785 : body_mass_kg [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 3:\n",
      "\t1296 : bill_length_mm [NUMERICAL]\n",
      "\t1133 : body_mass_kg [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 5:\n",
      "\t1412 : bill_length_mm [NUMERICAL]\n",
      "\t1257 : body_mass_kg [NUMERICAL]\n",
      "\n",
      "Condition type in nodes:\n",
      "\t2672 : HigherCondition\n",
      "Condition type in nodes with depth <= 0:\n",
      "\t300 : HigherCondition\n",
      "Condition type in nodes with depth <= 1:\n",
      "\t878 : HigherCondition\n",
      "Condition type in nodes with depth <= 2:\n",
      "\t1734 : HigherCondition\n",
      "Condition type in nodes with depth <= 3:\n",
      "\t2429 : HigherCondition\n",
      "Condition type in nodes with depth <= 5:\n",
      "\t2669 : HigherCondition\n",
      "Node format: NOT_SET\n",
      "\n",
      "Training OOB:\n",
      "\ttrees: 1, Out-of-bag evaluation: accuracy:0.891304 logloss:3.91779\n",
      "\ttrees: 11, Out-of-bag evaluation: accuracy:0.92623 logloss:1.68309\n",
      "\ttrees: 21, Out-of-bag evaluation: accuracy:0.927126 logloss:1.24847\n",
      "\ttrees: 31, Out-of-bag evaluation: accuracy:0.927126 logloss:1.24752\n",
      "\ttrees: 41, Out-of-bag evaluation: accuracy:0.919355 logloss:0.969757\n",
      "\ttrees: 52, Out-of-bag evaluation: accuracy:0.91129 logloss:0.83518\n",
      "\ttrees: 63, Out-of-bag evaluation: accuracy:0.915323 logloss:0.700303\n",
      "\ttrees: 74, Out-of-bag evaluation: accuracy:0.915323 logloss:0.568588\n",
      "\ttrees: 84, Out-of-bag evaluation: accuracy:0.919355 logloss:0.564567\n",
      "\ttrees: 95, Out-of-bag evaluation: accuracy:0.931452 logloss:0.567189\n",
      "\ttrees: 108, Out-of-bag evaluation: accuracy:0.927419 logloss:0.566625\n",
      "\ttrees: 118, Out-of-bag evaluation: accuracy:0.923387 logloss:0.568866\n",
      "\ttrees: 129, Out-of-bag evaluation: accuracy:0.923387 logloss:0.569575\n",
      "\ttrees: 140, Out-of-bag evaluation: accuracy:0.923387 logloss:0.568819\n",
      "\ttrees: 151, Out-of-bag evaluation: accuracy:0.923387 logloss:0.569744\n",
      "\ttrees: 163, Out-of-bag evaluation: accuracy:0.927419 logloss:0.569485\n",
      "\ttrees: 174, Out-of-bag evaluation: accuracy:0.927419 logloss:0.569312\n",
      "\ttrees: 186, Out-of-bag evaluation: accuracy:0.927419 logloss:0.569888\n",
      "\ttrees: 196, Out-of-bag evaluation: accuracy:0.927419 logloss:0.571099\n",
      "\ttrees: 206, Out-of-bag evaluation: accuracy:0.927419 logloss:0.570791\n",
      "\ttrees: 216, Out-of-bag evaluation: accuracy:0.927419 logloss:0.570381\n",
      "\ttrees: 227, Out-of-bag evaluation: accuracy:0.927419 logloss:0.571072\n",
      "\ttrees: 238, Out-of-bag evaluation: accuracy:0.927419 logloss:0.571894\n",
      "\ttrees: 249, Out-of-bag evaluation: accuracy:0.927419 logloss:0.572864\n",
      "\ttrees: 260, Out-of-bag evaluation: accuracy:0.927419 logloss:0.573197\n",
      "\ttrees: 270, Out-of-bag evaluation: accuracy:0.927419 logloss:0.572408\n",
      "\ttrees: 280, Out-of-bag evaluation: accuracy:0.927419 logloss:0.571476\n",
      "\ttrees: 290, Out-of-bag evaluation: accuracy:0.927419 logloss:0.571359\n",
      "\ttrees: 300, Out-of-bag evaluation: accuracy:0.927419 logloss:0.571626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%set_cell_height 300\n",
    "\n",
    "body_mass_g = tf_keras.layers.Input(shape=(1,), name=\"body_mass_g\")\n",
    "body_mass_kg = body_mass_g / 1000.0\n",
    "\n",
    "bill_length_mm = tf_keras.layers.Input(shape=(1,), name=\"bill_length_mm\")\n",
    "\n",
    "raw_inputs = {\"body_mass_g\": body_mass_g, \"bill_length_mm\": bill_length_mm}\n",
    "processed_inputs = {\"body_mass_kg\": body_mass_kg, \"bill_length_mm\": bill_length_mm}\n",
    "\n",
    "# \"preprocessor\" contains the preprocessing logic.\n",
    "preprocessor = tf_keras.Model(inputs=raw_inputs, outputs=processed_inputs)\n",
    "\n",
    "# \"model_4\" contains both the pre-processing logic and the decision forest.\n",
    "model_4 = tfdf.keras.RandomForestModel(preprocessing=preprocessor)\n",
    "model_4.fit(train_ds)\n",
    "\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1Bx3Feyjb2o"
   },
   "source": [
    "The following example re-implements the same logic using TensorFlow Feature\n",
    "Columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fnwe3sBt-yJk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.041174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 13 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x7fe4202549d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:44.8808 UTC kernel.cc:1233] Loading model from path /tmpfs/tmp/tmpqc51ghzt/model/ with prefix 2e9db5c6f4514133\n",
      "[INFO 24-01-31 12:18:44.8970 UTC decision_forest.cc:660] Model loaded with 300 root(s), 5644 node(s), and 2 input feature(s).\n",
      "[INFO 24-01-31 12:18:44.8970 UTC kernel.cc:1061] Use fast generic engine\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x7fe4202549d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7fe42048e6a0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def g_to_kg(x):\n",
    "  return x / 1000\n",
    "\n",
    "feature_columns = [\n",
    "    tf.feature_column.numeric_column(\"body_mass_g\", normalizer_fn=g_to_kg),\n",
    "    tf.feature_column.numeric_column(\"bill_length_mm\"),\n",
    "]\n",
    "\n",
    "preprocessing = tf_keras.layers.DenseFeatures(feature_columns)\n",
    "\n",
    "model_5 = tfdf.keras.RandomForestModel(preprocessing=preprocessing)\n",
    "model_5.fit(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vif6gsAjfzv"
   },
   "source": [
    "## Training a regression model\n",
    "\n",
    "The previous example trains a classification model (TF-DF does not differentiate\n",
    "between binary classification and multi-class classification). In the next\n",
    "example, train a regression model on the\n",
    "[Abalone dataset](https://archive.ics.uci.edu/ml/datasets/abalone). The\n",
    "objective of this dataset is to predict the number of shell's rings of an\n",
    "abalone.\n",
    "\n",
    "**Note:** The csv file is assembled by appending UCI's header and data files. No preprocessing was applied.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/33/LivingAbalone.JPG/800px-LivingAbalone.JPG\" width=\"200\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0uKI_Uy7RyWN"
   },
   "outputs": [],
   "source": [
    "# Download the dataset.\n",
    "!wget -q https://storage.googleapis.com/download.tensorflow.org/data/abalone_raw.csv -O /tmp/abalone.csv\n",
    "\n",
    "dataset_df = pd.read_csv(\"/tmp/abalone.csv\")\n",
    "print(dataset_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_gjrquQySU7Q"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into a training and testing dataset.\n",
    "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
    "print(\"{} examples in training, {} examples for testing.\".format(\n",
    "    len(train_ds_pd), len(test_ds_pd)))\n",
    "\n",
    "# Name of the label column.\n",
    "label = \"Rings\"\n",
    "\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8fUhQKISqYT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 24-01-31 12:18:46.9600 UTC decision_forest.cc:660] Model loaded with 300 root(s), 259684 node(s), and 8 input feature(s).\n",
      "[INFO 24-01-31 12:18:46.9600 UTC kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7fe6240aafd0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%set_cell_height 300\n",
    "\n",
    "# Configure the model.\n",
    "model_7 = tfdf.keras.RandomForestModel(task = tfdf.keras.Task.REGRESSION)\n",
    "\n",
    "# Train the model.\n",
    "model_7.fit(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aSriIAaMSzwA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.0000e+00 - mse: 4.8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'mse': 4.820103168487549}\n",
      "\n",
      "MSE: 4.820103168487549\n",
      "RMSE: 2.1954733358634875\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset.\n",
    "model_7.compile(metrics=[\"mse\"])\n",
    "evaluation = model_7.evaluate(test_ds, return_dict=True)\n",
    "\n",
    "print(evaluation)\n",
    "print()\n",
    "print(f\"MSE: {evaluation['mse']}\")\n",
    "print(f\"RMSE: {math.sqrt(evaluation['mse'])}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "beginner_colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
