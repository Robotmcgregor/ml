{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbf0c2f0",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837539f7",
   "metadata": {},
   "source": [
    "![Nural Networks](nn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b891783b",
   "metadata": {},
   "source": [
    "![Nural Networks 2](nn2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f5987b",
   "metadata": {},
   "source": [
    "![Neral network tip](nn3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6533cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "365b8adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabeties = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ac4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "train_x, train_y = diabeties.data[:400], diabeties.target[:400]\n",
    "test_x, test_y = diabeties.data[400:], diabeties.target[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0675741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpr = MLPRegressor(solver='sgd')\n",
    "mlpr.fit(train_x, train_y)\n",
    "err = metrics.mean_squared_error(test_y, mlpr.predict(test_x))\n",
    "r2 = metrics.r2_score(test_y, mlpr.predict(test_x))\n",
    "rmse = np.sqrt(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84d83df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---OLS on diabeties dataset---\n",
      "--------------------\n",
      "R squared: 0.68  MSE: 1749.12 \n",
      "  RMSE: 41.82 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"---OLS on diabeties dataset---\")\n",
    "#print(\"Coefficents: \")\n",
    "#print(\"Intecept (b): %.2f\"%mlpr.intercept_)\n",
    "# for i in range(len(diabeties.feature_names)):\n",
    "#     print(diabeties.feature_names[i]+\"0: %.2f\" %mlpr.coef_[i])\n",
    "print(\"-\"*20)\n",
    "rmse = np.sqrt(err)\n",
    "print(\"R squared: %.2f\"%r2, ' MSE: %.2f \\n' %err, ' RMSE: %.2f \\n' %rmse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37a87e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---adam MLPRegressor on diabeties dataset---\n",
      "R squared: 0.35  MSE: 3438.15 \n",
      "  RMSE: 58.64 \n",
      "\n",
      "-\n",
      "---adam MLPRegressor on diabeties dataset---\n",
      "R squared: -0.01  MSE: 5340.77 \n",
      "  RMSE: 73.08 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robot\\anaconda3\\envs\\tf_grid\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "#from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generate synthetic data\n",
    "X = diabeties.data\n",
    "Y = diabeties.target\n",
    "# X, y = diabeties(n_samples=1000, n_features=10, noise=0.1, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train MLPRegressor with Adam optimizer\n",
    "mlp_regressor_adam = MLPRegressor(hidden_layer_sizes=(100, 50), solver='adam', random_state=42)\n",
    "mlp_regressor_adam.fit(X_train, y_train)\n",
    "y_pred_adam = mlp_regressor_adam.predict(X_test)\n",
    "\n",
    "err = metrics.mean_squared_error(y_test, mlp_regressor_adam.predict(X_test))\n",
    "r2 = metrics.r2_score(y_test, mlp_regressor_adam.predict(X_test))\n",
    "rmse = np.sqrt(err)\n",
    "\n",
    "print(\"---adam MLPRegressor on diabeties dataset---\")\n",
    "rmse = np.sqrt(err)\n",
    "print(\"R squared: %.2f\"%r2, ' MSE: %.2f \\n' %err, ' RMSE: %.2f \\n' %rmse) \n",
    "print(\"-\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Train MLPRegressor with stochastic gradient descent (SGD) optimizer\n",
    "mlp_regressor_sgd = MLPRegressor(hidden_layer_sizes=(20, 2), solver='sgd', random_state=42)\n",
    "mlp_regressor_sgd.fit(X_train, y_train)\n",
    "y_pred_sgd = mlp_regressor_sgd.predict(X_test)\n",
    "\n",
    "err = metrics.mean_squared_error(y_test, mlp_regressor_sgd.predict(X_test))\n",
    "r2 = metrics.r2_score(y_test, mlp_regressor_sgd.predict(X_test))\n",
    "rmse = np.sqrt(err)\n",
    "\n",
    "print(\"---adam MLPRegressor on diabeties dataset---\")\n",
    "rmse = np.sqrt(err)\n",
    "print(\"R squared: %.2f\"%r2, ' MSE: %.2f \\n' %err, ' RMSE: %.2f \\n' %rmse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e775ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADAM Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4e4d321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hidden layer sizes: (100, 100)\n",
      "---adam MLPRegressor on diabeties dataset---\n",
      "R squared: 0.38  MSE: 3292.87 \n",
      "  RMSE: 57.38 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robot\\anaconda3\\envs\\ml_py37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generate synthetic data\n",
    "#X, y = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define MLPRegressor model\n",
    "mlp_regressor = MLPRegressor(random_state=42, solver='adam')\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (100, 100)],\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(mlp_regressor, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hidden layer sizes:\", best_params['hidden_layer_sizes'])\n",
    "\n",
    "# Evaluate model with best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "\n",
    "err = metrics.mean_squared_error(y_test, best_model.predict(X_test))\n",
    "r2 = metrics.r2_score(y_test, best_model.predict(X_test))\n",
    "rmse = np.sqrt(err)\n",
    "\n",
    "print(\"---adam MLPRegressor on diabeties dataset---\")\n",
    "rmse = np.sqrt(err)\n",
    "print(\"R squared: %.2f\"%r2, ' MSE: %.2f \\n' %err, ' RMSE: %.2f \\n' %rmse) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22012ab6",
   "metadata": {},
   "source": [
    "## SGD Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68c52061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hidden layer sizes: (50,)\n",
      "---adam MLPRegressor on diabeties dataset---\n",
      "R squared: 0.46  MSE: 2883.89 \n",
      "  RMSE: 53.70 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generate synthetic data\n",
    "#X, y = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define MLPRegressor model\n",
    "mlp_regressor = MLPRegressor(random_state=42, solver='sgd')\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (100, 100)],\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(mlp_regressor, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hidden layer sizes:\", best_params['hidden_layer_sizes'])\n",
    "\n",
    "# Evaluate model with best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "\n",
    "err = metrics.mean_squared_error(y_test, best_model.predict(X_test))\n",
    "r2 = metrics.r2_score(y_test, best_model.predict(X_test))\n",
    "rmse = np.sqrt(err)\n",
    "\n",
    "print(\"---adam MLPRegressor on diabeties dataset---\")\n",
    "rmse = np.sqrt(err)\n",
    "print(\"R squared: %.2f\"%r2, ' MSE: %.2f \\n' %err, ' RMSE: %.2f \\n' %rmse) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c63c6af",
   "metadata": {},
   "source": [
    "## LBFGS Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00efa47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hidden layer sizes: (100, 50)\n",
      "---adam MLPRegressor on diabeties dataset---\n",
      "R squared: 0.53  MSE: 2482.49 \n",
      "  RMSE: 49.82 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generate synthetic data\n",
    "#X, y = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define MLPRegressor model\n",
    "mlp_regressor = MLPRegressor(random_state=42, solver='lbfgs')\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (100, 100)],\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(mlp_regressor, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hidden layer sizes:\", best_params['hidden_layer_sizes'])\n",
    "\n",
    "# Evaluate model with best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "\n",
    "err = metrics.mean_squared_error(y_test, best_model.predict(X_test))\n",
    "r2 = metrics.r2_score(y_test, best_model.predict(X_test))\n",
    "rmse = np.sqrt(err)\n",
    "\n",
    "print(\"---adam MLPRegressor on diabeties dataset---\")\n",
    "rmse = np.sqrt(err)\n",
    "print(\"R squared: %.2f\"%r2, ' MSE: %.2f \\n' %err, ' RMSE: %.2f \\n' %rmse) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c736a6f",
   "metadata": {},
   "source": [
    "### SAve best model to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b66e216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "with open('mlp_regressor_model_100-50_lbfgs.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57f3af6",
   "metadata": {},
   "source": [
    "### Import Pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "577b87d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model from file\n",
    "with open('mlp_regressor_model_100-50_lbfgs.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "# Use the model for further analysis\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "607bd2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([159.81369803, 187.74272642, 145.97598137, 309.13824688,\n",
       "       106.83332338, 103.42830648, 281.15269208, 190.97215848,\n",
       "        81.64567307,  92.49398307, 116.752698  , 164.85310489,\n",
       "        83.88533314, 220.63898148,  90.27507118, 119.66036048,\n",
       "       237.77307944, 284.2242292 , 203.35346667, 237.29562449,\n",
       "       205.80595829,  96.58481304,  77.79316741, 204.95584678,\n",
       "       144.48904802, 170.88742323, 202.7009899 , 184.56617224,\n",
       "        80.2036682 , 101.55818134, 169.57734505, 112.37150254,\n",
       "       114.14917743, 186.88748374, 173.82231667, 185.04281319,\n",
       "       105.93029543, 105.14948753, 151.25432424,  77.29214536,\n",
       "        71.44844417, 117.79155526, 165.03304109, 161.55185171,\n",
       "       172.09383361,  83.96766312,  93.09214352,  87.1173935 ,\n",
       "        73.96658574, 174.57758078, 136.67781428, 115.29500388,\n",
       "        97.51807231,  89.25518533, 159.48087369, 140.59840757,\n",
       "        99.26190398, 226.28406695, 128.7459902 ,  82.23245665,\n",
       "       183.96756785, 195.49464781, 117.75980217, 101.53320959,\n",
       "       143.07225732, 212.5510024 , 150.25167675, 164.84741934,\n",
       "       154.7293128 , 117.08567301, 151.95318819, 196.60806044,\n",
       "       241.87168754, 116.13370684,  75.86678937, 134.0689247 ,\n",
       "       192.34536338, 200.29507641, 162.88081868, 182.47815314,\n",
       "       117.71332206, 151.06416265,  95.95342137,  78.25154392,\n",
       "       101.16458495,  71.17467665,  84.75572332,  74.40139248,\n",
       "       160.28935416])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6582799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
