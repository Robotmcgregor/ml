{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1155e19",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "073a6173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e027d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabeties = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4128bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabeties.data\n",
    "Y = diabeties.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c93bdc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "353/353 [==============================] - 0s 286us/step - loss: 29680.3815 - mean_squared_error: 29680.3815\n",
      "Epoch 2/100\n",
      "353/353 [==============================] - 0s 24us/step - loss: 29597.5113 - mean_squared_error: 29597.5113\n",
      "Epoch 3/100\n",
      "353/353 [==============================] - 0s 24us/step - loss: 29448.5211 - mean_squared_error: 29448.5211\n",
      "Epoch 4/100\n",
      "353/353 [==============================] - 0s 21us/step - loss: 29192.2009 - mean_squared_error: 29192.2009\n",
      "Epoch 5/100\n",
      "353/353 [==============================] - 0s 26us/step - loss: 28789.6719 - mean_squared_error: 28789.6719\n",
      "Epoch 6/100\n",
      "353/353 [==============================] - 0s 21us/step - loss: 28177.0625 - mean_squared_error: 28177.0625\n",
      "Epoch 7/100\n",
      "353/353 [==============================] - 0s 26us/step - loss: 27280.0845 - mean_squared_error: 27280.0845\n",
      "Epoch 8/100\n",
      "353/353 [==============================] - 0s 22us/step - loss: 26076.2385 - mean_squared_error: 26076.2385\n",
      "Epoch 9/100\n",
      "353/353 [==============================] - 0s 23us/step - loss: 24523.7834 - mean_squared_error: 24523.7834\n",
      "Epoch 10/100\n",
      "353/353 [==============================] - 0s 17us/step - loss: 22661.4815 - mean_squared_error: 22661.4815\n",
      "Epoch 11/100\n",
      "353/353 [==============================] - 0s 19us/step - loss: 20515.7865 - mean_squared_error: 20515.7865\n",
      "Epoch 12/100\n",
      "353/353 [==============================] - 0s 16us/step - loss: 18190.2715 - mean_squared_error: 18190.2715\n",
      "Epoch 13/100\n",
      "353/353 [==============================] - 0s 17us/step - loss: 15622.9672 - mean_squared_error: 15622.9672\n",
      "Epoch 14/100\n",
      "353/353 [==============================] - 0s 14us/step - loss: 13021.3016 - mean_squared_error: 13021.3016\n",
      "Epoch 15/100\n",
      "353/353 [==============================] - 0s 20us/step - loss: 10627.5046 - mean_squared_error: 10627.5046\n",
      "Epoch 16/100\n",
      "353/353 [==============================] - 0s 15us/step - loss: 8404.9503 - mean_squared_error: 8404.9503\n",
      "Epoch 17/100\n",
      "353/353 [==============================] - 0s 21us/step - loss: 6684.2488 - mean_squared_error: 6684.2488\n",
      "Epoch 18/100\n",
      "353/353 [==============================] - 0s 14us/step - loss: 5501.9899 - mean_squared_error: 5501.9899\n",
      "Epoch 19/100\n",
      "353/353 [==============================] - 0s 13us/step - loss: 4840.1105 - mean_squared_error: 4840.1105\n",
      "Epoch 20/100\n",
      "353/353 [==============================] - 0s 20us/step - loss: 4494.8473 - mean_squared_error: 4494.8473\n",
      "Epoch 21/100\n",
      "353/353 [==============================] - 0s 13us/step - loss: 4324.0440 - mean_squared_error: 4324.0440\n",
      "Epoch 22/100\n",
      "353/353 [==============================] - 0s 10us/step - loss: 4203.9534 - mean_squared_error: 4203.9534\n",
      "Epoch 23/100\n",
      "353/353 [==============================] - 0s 22us/step - loss: 4126.3869 - mean_squared_error: 4126.3869\n",
      "Epoch 24/100\n",
      "353/353 [==============================] - 0s 13us/step - loss: 4063.5550 - mean_squared_error: 4063.5550\n",
      "Epoch 25/100\n",
      "353/353 [==============================] - 0s 21us/step - loss: 4012.6687 - mean_squared_error: 4012.6687\n",
      "Epoch 26/100\n",
      "353/353 [==============================] - 0s 15us/step - loss: 3957.4225 - mean_squared_error: 3957.4225\n",
      "Epoch 27/100\n",
      "353/353 [==============================] - 0s 12us/step - loss: 3895.6405 - mean_squared_error: 3895.6405\n",
      "Epoch 28/100\n",
      "353/353 [==============================] - 0s 14us/step - loss: 3838.4480 - mean_squared_error: 3838.4480\n",
      "Epoch 29/100\n",
      "353/353 [==============================] - 0s 14us/step - loss: 3787.3067 - mean_squared_error: 3787.3067\n",
      "Epoch 30/100\n",
      "353/353 [==============================] - 0s 12us/step - loss: 3748.6059 - mean_squared_error: 3748.6059\n",
      "Epoch 31/100\n",
      "353/353 [==============================] - 0s 20us/step - loss: 3711.3574 - mean_squared_error: 3711.3574\n",
      "Epoch 32/100\n",
      "353/353 [==============================] - 0s 13us/step - loss: 3674.6227 - mean_squared_error: 3674.6227\n",
      "Epoch 33/100\n",
      "353/353 [==============================] - 0s 15us/step - loss: 3633.7340 - mean_squared_error: 3633.7340\n",
      "Epoch 34/100\n",
      "353/353 [==============================] - 0s 12us/step - loss: 3608.0697 - mean_squared_error: 3608.0697\n",
      "Epoch 35/100\n",
      "353/353 [==============================] - 0s 15us/step - loss: 3572.5722 - mean_squared_error: 3572.5722\n",
      "Epoch 36/100\n",
      "353/353 [==============================] - 0s 14us/step - loss: 3539.9659 - mean_squared_error: 3539.9659\n",
      "Epoch 37/100\n",
      "353/353 [==============================] - 0s 12us/step - loss: 3513.5393 - mean_squared_error: 3513.5393\n",
      "Epoch 38/100\n",
      "353/353 [==============================] - 0s 19us/step - loss: 3482.6584 - mean_squared_error: 3482.6584\n",
      "Epoch 39/100\n",
      "353/353 [==============================] - 0s 12us/step - loss: 3452.1897 - mean_squared_error: 3452.1897\n",
      "Epoch 40/100\n",
      "353/353 [==============================] - 0s 11us/step - loss: 3425.9332 - mean_squared_error: 3425.9332\n",
      "Epoch 41/100\n",
      "353/353 [==============================] - 0s 24us/step - loss: 3407.4216 - mean_squared_error: 3407.4216\n",
      "Epoch 42/100\n",
      "353/353 [==============================] - 0s 13us/step - loss: 3383.2780 - mean_squared_error: 3383.2780\n",
      "Epoch 43/100\n",
      "353/353 [==============================] - 0s 13us/step - loss: 3379.4203 - mean_squared_error: 3379.4203\n",
      "Epoch 44/100\n",
      "353/353 [==============================] - 0s 21us/step - loss: 3343.1937 - mean_squared_error: 3343.1937\n",
      "Epoch 45/100\n",
      "353/353 [==============================] - 0s 12us/step - loss: 3339.9685 - mean_squared_error: 3339.9685\n",
      "Epoch 46/100\n",
      "353/353 [==============================] - 0s 33us/step - loss: 3341.0030 - mean_squared_error: 3341.0030\n",
      "Epoch 47/100\n",
      "353/353 [==============================] - 0s 24us/step - loss: 3306.7643 - mean_squared_error: 3306.7643\n",
      "Epoch 48/100\n",
      "353/353 [==============================] - 0s 27us/step - loss: 3276.2885 - mean_squared_error: 3276.2885\n",
      "Epoch 49/100\n",
      "353/353 [==============================] - 0s 21us/step - loss: 3261.5127 - mean_squared_error: 3261.5127\n",
      "Epoch 50/100\n",
      "353/353 [==============================] - 0s 15us/step - loss: 3260.4152 - mean_squared_error: 3260.4152\n",
      "Epoch 51/100\n",
      "353/353 [==============================] - 0s 15us/step - loss: 3273.2805 - mean_squared_error: 3273.2805\n",
      "Epoch 52/100\n",
      "353/353 [==============================] - 0s 15us/step - loss: 3215.1556 - mean_squared_error: 3215.1556\n",
      "Epoch 53/100\n",
      "353/353 [==============================] - 0s 12us/step - loss: 3208.9477 - mean_squared_error: 3208.9477\n",
      "Epoch 54/100\n",
      "353/353 [==============================] - 0s 17us/step - loss: 3187.8749 - mean_squared_error: 3187.8749\n",
      "Epoch 55/100\n",
      "353/353 [==============================] - 0s 12us/step - loss: 3174.2840 - mean_squared_error: 3174.2840\n",
      "Epoch 56/100\n",
      "353/353 [==============================] - 0s 18us/step - loss: 3161.3183 - mean_squared_error: 3161.3183\n",
      "Epoch 57/100\n",
      "353/353 [==============================] - 0s 12us/step - loss: 3152.2578 - mean_squared_error: 3152.2578\n",
      "Epoch 58/100\n",
      "353/353 [==============================] - 0s 20us/step - loss: 3141.6015 - mean_squared_error: 3141.6015\n",
      "Epoch 59/100\n",
      "353/353 [==============================] - 0s 13us/step - loss: 3132.2488 - mean_squared_error: 3132.2488\n",
      "Epoch 60/100\n",
      "353/353 [==============================] - 0s 22us/step - loss: 3126.3352 - mean_squared_error: 3126.3352\n",
      "Epoch 61/100\n",
      "353/353 [==============================] - 0s 16us/step - loss: 3118.7063 - mean_squared_error: 3118.7063\n",
      "Epoch 62/100\n",
      "353/353 [==============================] - 0s 15us/step - loss: 3106.2231 - mean_squared_error: 3106.2231\n",
      "Epoch 63/100\n",
      "353/353 [==============================] - 0s 15us/step - loss: 3109.3568 - mean_squared_error: 3109.3568\n",
      "Epoch 64/100\n",
      "353/353 [==============================] - 0s 12us/step - loss: 3120.0244 - mean_squared_error: 3120.0244\n",
      "Epoch 65/100\n",
      "353/353 [==============================] - 0s 12us/step - loss: 3133.0309 - mean_squared_error: 3133.0309\n",
      "Epoch 66/100\n",
      "353/353 [==============================] - 0s 15us/step - loss: 3115.1750 - mean_squared_error: 3115.1750\n",
      "Epoch 67/100\n",
      "353/353 [==============================] - 0s 15us/step - loss: 3077.0733 - mean_squared_error: 3077.0733\n",
      "Epoch 68/100\n",
      "353/353 [==============================] - 0s 17us/step - loss: 3077.5116 - mean_squared_error: 3077.5116\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353/353 [==============================] - 0s 15us/step - loss: 3070.2133 - mean_squared_error: 3070.2133\n",
      "Epoch 70/100\n",
      "353/353 [==============================] - 0s 15us/step - loss: 3069.0091 - mean_squared_error: 3069.0091\n",
      "Epoch 71/100\n",
      "353/353 [==============================] - 0s 14us/step - loss: 3069.6655 - mean_squared_error: 3069.6655\n",
      "Epoch 72/100\n",
      "353/353 [==============================] - 0s 15us/step - loss: 3066.3823 - mean_squared_error: 3066.3823\n",
      "Epoch 73/100\n",
      "353/353 [==============================] - 0s 12us/step - loss: 3057.9088 - mean_squared_error: 3057.9088\n",
      "Epoch 74/100\n",
      "353/353 [==============================] - 0s 13us/step - loss: 3046.2556 - mean_squared_error: 3046.2556\n",
      "Epoch 75/100\n",
      "353/353 [==============================] - 0s 15us/step - loss: 3043.1291 - mean_squared_error: 3043.1291\n",
      "Epoch 76/100\n",
      "353/353 [==============================] - 0s 12us/step - loss: 3046.4443 - mean_squared_error: 3046.4443\n",
      "Epoch 77/100\n",
      "353/353 [==============================] - 0s 13us/step - loss: 3028.8670 - mean_squared_error: 3028.8670\n",
      "Epoch 78/100\n",
      "353/353 [==============================] - 0s 12us/step - loss: 3021.5785 - mean_squared_error: 3021.5785\n",
      "Epoch 79/100\n",
      "353/353 [==============================] - 0s 12us/step - loss: 3024.6851 - mean_squared_error: 3024.6851\n",
      "Epoch 80/100\n",
      "353/353 [==============================] - 0s 24us/step - loss: 3013.9216 - mean_squared_error: 3013.9216\n",
      "Epoch 81/100\n",
      "353/353 [==============================] - 0s 22us/step - loss: 3002.5180 - mean_squared_error: 3002.5180\n",
      "Epoch 82/100\n",
      "353/353 [==============================] - 0s 26us/step - loss: 3014.8151 - mean_squared_error: 3014.8151\n",
      "Epoch 83/100\n",
      "353/353 [==============================] - 0s 24us/step - loss: 3011.1125 - mean_squared_error: 3011.1125\n",
      "Epoch 84/100\n",
      "353/353 [==============================] - 0s 12us/step - loss: 2997.6773 - mean_squared_error: 2997.6773\n",
      "Epoch 85/100\n",
      "353/353 [==============================] - 0s 25us/step - loss: 2987.0187 - mean_squared_error: 2987.0187\n",
      "Epoch 86/100\n",
      "353/353 [==============================] - 0s 21us/step - loss: 2984.5192 - mean_squared_error: 2984.5192\n",
      "Epoch 87/100\n",
      "353/353 [==============================] - 0s 12us/step - loss: 2992.0736 - mean_squared_error: 2992.0736\n",
      "Epoch 88/100\n",
      "353/353 [==============================] - 0s 15us/step - loss: 3029.8968 - mean_squared_error: 3029.8968\n",
      "Epoch 89/100\n",
      "353/353 [==============================] - 0s 20us/step - loss: 2997.0436 - mean_squared_error: 2997.0436\n",
      "Epoch 90/100\n",
      "353/353 [==============================] - 0s 14us/step - loss: 2975.9866 - mean_squared_error: 2975.9866\n",
      "Epoch 91/100\n",
      "353/353 [==============================] - 0s 22us/step - loss: 2966.9673 - mean_squared_error: 2966.9673\n",
      "Epoch 92/100\n",
      "353/353 [==============================] - 0s 12us/step - loss: 2975.2270 - mean_squared_error: 2975.2270\n",
      "Epoch 93/100\n",
      "353/353 [==============================] - 0s 22us/step - loss: 2961.7293 - mean_squared_error: 2961.7293\n",
      "Epoch 94/100\n",
      "353/353 [==============================] - 0s 20us/step - loss: 2958.1009 - mean_squared_error: 2958.1009\n",
      "Epoch 95/100\n",
      "353/353 [==============================] - 0s 12us/step - loss: 2951.6062 - mean_squared_error: 2951.6062\n",
      "Epoch 96/100\n",
      "353/353 [==============================] - 0s 22us/step - loss: 2951.7938 - mean_squared_error: 2951.7938\n",
      "Epoch 97/100\n",
      "353/353 [==============================] - 0s 13us/step - loss: 2948.8773 - mean_squared_error: 2948.8773\n",
      "Epoch 98/100\n",
      "353/353 [==============================] - 0s 19us/step - loss: 2952.2944 - mean_squared_error: 2952.2944\n",
      "Epoch 99/100\n",
      "353/353 [==============================] - 0s 16us/step - loss: 2949.7658 - mean_squared_error: 2949.7658\n",
      "Epoch 100/100\n",
      "353/353 [==============================] - 0s 13us/step - loss: 2944.4573 - mean_squared_error: 2944.4573\n",
      "89/89 [==============================] - 0s 177us/step\n",
      "Mean Squared Error: 2854.73088570927\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=10, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = model.evaluate(X_test, y_test)[1]\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7544f64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_37780\\1888834699.py:26: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002244E2D6F80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000022440B42C20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Best Parameters: {'activation': 'tanh', 'layers': (100, 50), 'optimizer': 'rmsprop'}\n",
      "---ANN on random dataset---\n",
      "R squared: -3.96  MSE: 26289.42 \n",
      "  RMSE: 162.14 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Function to create model\n",
    "def create_model(layers=(100, 50), activation='relu', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layers[0], input_dim=10, activation=activation))\n",
    "    for units in layers[1:]:\n",
    "        model.add(Dense(units, activation=activation))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mean_squared_error'])\n",
    "    return model\n",
    "\n",
    "# Generate synthetic data\n",
    "#X, Y = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create KerasRegressor\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Define the grid search parameters\n",
    "param_grid = {\n",
    "    'layers': [(100,), (100, 50), (50, 50), (50, 25)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'optimizer': ['adam', 'rmsprop'],#, 'sgd']\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_result.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model = grid_result.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "err = metrics.mean_squared_error(y_test, best_model.predict(X_test))\n",
    "r2 = metrics.r2_score(y_test, best_model.predict(X_test))\n",
    "rmse = np.sqrt(err)\n",
    "\n",
    "print(\"---ANN on random dataset---\")\n",
    "rmse = np.sqrt(err)\n",
    "print(\"R squared: %.2f\"%r2, ' MSE: %.2f \\n' %err, ' RMSE: %.2f \\n' %rmse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c461072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_37780\\2908258862.py:13: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_regressor = KerasRegressor(build_fn=create_model, epochs=50, batch_size=32, verbose=0)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 23\u001b[0m\n\u001b[0;32m     16\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munits\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m],\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     20\u001b[0m }\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Create the pipeline\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mPipeline\u001b[49m([\n\u001b[0;32m     24\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()),  \u001b[38;5;66;03m# Optional: scaling input features\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras\u001b[39m\u001b[38;5;124m'\u001b[39m, keras_regressor)\n\u001b[0;32m     26\u001b[0m ])\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Perform grid search with cross-validation\u001b[39;00m\n\u001b[0;32m     29\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mpipeline, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the KerasRegressor model function\n",
    "def create_model(units=32, activation='relu', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, input_dim=X_train.shape[1], activation=activation))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Create KerasRegressor wrapper\n",
    "keras_regressor = KerasRegressor(build_fn=create_model, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'units': [32, 64, 128],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'optimizer': ['adam', 'rmsprop']\n",
    "}\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Optional: scaling input features\n",
    "    ('keras', keras_regressor)\n",
    "])\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Mean Squared Error:\", mse)\n",
    "err = metrics.mean_squared_error(y_test, best_model.predict(X_test))\n",
    "r2 = metrics.r2_score(y_test, best_model.predict(X_test))\n",
    "rmse = np.sqrt(err)\n",
    "\n",
    "print(\"---ANN on random dataset---\")\n",
    "rmse = np.sqrt(err)\n",
    "print(\"R squared: %.2f\"%r2, ' MSE: %.2f \\n' %err, ' RMSE: %.2f \\n' %rmse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb73052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
